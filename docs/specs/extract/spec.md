# 提取规范

## 目的
提取模块负责根据预定义模式将源模块的中间表示转换为结构化数据。

## 架构
提取模块是处理管道（pipeline）的核心组件，接收来自上游节点（sources）提供的 `pre_results` 作为输入数据。这些数据包含了所有已解析的源文件信息，提取模块负责将这些数据转换为结构化格式。

## 需求

### 需求：纯文本信息提取
系统应使用基于LLM的提取从纯文本文件中提取结构化信息。

#### 场景：从邮件正文中提取信息
- 当处理管道运行到提取模块时
- 系统从 `pre_results` 中获取纯文本文件（邮件正文）
- 系统使用LLM根据预定义的提示词和示例提取结构化信息
- 并将提取的数据保存为JSON文件
- 并处理每个文档的多个实体

#### 场景：LLM配置
- 当系统启动时
- 从环境变量加载模型配置（EXTRACT_MODEL_ID, EXTRACT_API_KEY, EXTRACT_BASE_URL）
- 并使用这些配置创建LLM模型实例

#### 场景：示例加载
- 当系统初始化时
- 从 `config/email.yaml` 文件加载提示词和示例数据
- 并使用这些示例来指导LLM进行信息提取

#### 场景：中文分词处理
- 当处理包含中文的文本时
- 系统使用jieba进行中文分词
- 并结合正则表达式进行英文、数字和符号的处理

#### 场景：结果保存
- 当信息提取完成后
- 系统将结果保存为JSON文件，文件名与原始文档名一致
- 并将结果传递给下游处理模块

### 需求：电子表格数据转换
系统应使用基于SQL的转换将电子表格数据（Parquet文件）转换为标准化格式。

#### 场景：转换Excel表格数据
- 当处理管道运行到提取模块时
- 系统从 `pre_results` 中获取Parquet文件（来自Excel表格）
- 系统使用LLM生成SQL脚本将列映射到标准化字段
- 并执行SQL来转换数据
- 并将转换后的数据保存为JSON文件

#### 场景：SQL生成
- 当处理Parquet文件时
- 系统使用LLM代理生成SQL脚本
- 并根据DataFrame的列名和预定义的映射规则生成查询语句

#### 场景：数据清理
- 当处理原始数据时
- 系统清理列名中的换行符、括号和空格
- 并处理日期格式的标准化

#### 场景：日期格式化
- 当处理包含日期的字段时
- 系统将日期字段格式化为标准的YYYY-MM-DD格式
- 并将年月字段格式化为YYYY-MM格式

### 需求：数据验证
系统应根据定义的模式验证提取的数据。

#### 场景：无效的提取数据
- 当提取的数据不符合模式时
- 系统记录验证错误
- 并尝试纠正或标记有问题的条目

#### 场景：SQL执行异常
- 当生成的SQL脚本执行失败时
- 系统记录错误信息
- 并尝试通过反思机制改进提示词

### 需求：模型集成
系统应与可配置的LLM提供商集成以进行文本提取。

#### 场景：配置LLM提供商
- 当设置了模型ID、API密钥和基础URL的环境变量时
- 系统使用指定的LLM提供商执行提取任务

#### 场景：多模型支持
- 当处理不同类型的数据时
- 系统支持为纯文本提取和电子表格转换配置不同的LLM模型
- 并分别通过EXTRACT_*和SPREAD_*环境变量进行配置

### 需求：错误处理
系统应在处理过程中优雅地处理各种错误。

#### 场景：JSON解析错误
- 当处理JSON数据时出现解析错误
- 系统记录错误并继续处理其他数据

#### 场景：文件处理错误
- 当处理文件时出现异常
- 系统记录错误并继续处理其他文件